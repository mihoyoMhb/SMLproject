{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T17:49:38.062061Z",
     "start_time": "2024-12-03T17:48:44.053777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "# 自定义预处理器\n",
    "class CustomPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "        self.weather_dummies_columns = None\n",
    "        self.categorical_features = None\n",
    "        self.numeric_features = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # 对数变换\n",
    "        X = X.copy()\n",
    "        X['visibility'] = np.log1p(X['visibility'])\n",
    "        X['snowdepth'] = np.log1p(X['snowdepth'])\n",
    "        X['precip'] = np.log1p(X['precip'])\n",
    "        # 时间特征转换\n",
    "        X['month_sin'] = np.sin(2 * np.pi * X['month'] / 12)\n",
    "        X['month_cos'] = np.cos(2 * np.pi * X['month'] / 12)\n",
    "        X['day_of_week_sin'] = np.sin(2 * np.pi * X['day_of_week'] / 7)\n",
    "        X['day_of_week_cos'] = np.cos(2 * np.pi * X['day_of_week'] / 7)\n",
    "        X['hour_of_day_sin'] = np.sin(2 * np.pi * X['hour_of_day'] / 24)\n",
    "        X['hour_of_day_cos'] = np.cos(2 * np.pi * X['hour_of_day'] / 24)\n",
    "        # 删除原始时间特征\n",
    "        X = X.drop(columns=['month', 'day_of_week', 'hour_of_day'], axis=1)\n",
    "        # 选择用于聚类的特征\n",
    "        clustering_features = ['summertime', 'temp', 'dew', 'humidity', 'snowdepth', 'windspeed', 'cloudcover', 'visibility', 'precip', 'snow']\n",
    "        # 在训练数据上拟合 KMeans\n",
    "        self.kmeans.fit(X[clustering_features])\n",
    "        # 添加聚类结果\n",
    "        X['weather_cluster'] = self.kmeans.labels_\n",
    "        # 映射聚类标签到天气质量\n",
    "        X['weather_quality'] = X['weather_cluster'].apply(self.label_weather_cluster)\n",
    "        # One-Hot 编码\n",
    "        weather_dummies = pd.get_dummies(X['weather_quality'], prefix='weather', drop_first=True)\n",
    "        # 保存天气哑变量的列名\n",
    "        self.weather_dummies_columns = weather_dummies.columns\n",
    "        X = pd.concat([X, weather_dummies], axis=1)\n",
    "        # 选择特征\n",
    "        weather_features = ['summertime', 'temp', 'dew', 'humidity', 'snowdepth', 'windspeed', 'cloudcover', 'visibility', 'precip', 'snow']\n",
    "        self.categorical_features = ['holiday', 'weekday'] + list(self.weather_dummies_columns)\n",
    "        self.numeric_features = [col for col in X.columns if col not in ['holiday', 'weekday', 'increase_stock', 'weather_cluster', 'weather_quality'] + list(self.weather_dummies_columns) + weather_features]\n",
    "        # 转换布尔类型\n",
    "        for col in X.select_dtypes(include=['bool']).columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "        # 在训练数据上拟合 StandardScaler\n",
    "        self.scaler.fit(X[self.numeric_features])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # 对数变换\n",
    "        X['visibility'] = np.log1p(X['visibility'])\n",
    "        X['snowdepth'] = np.log1p(X['snowdepth'])\n",
    "        X['precip'] = np.log1p(X['precip'])\n",
    "        # 时间特征转换\n",
    "        X['month_sin'] = np.sin(2 * np.pi * X['month'] / 12)\n",
    "        X['month_cos'] = np.cos(2 * np.pi * X['month'] / 12)\n",
    "        X['day_of_week_sin'] = np.sin(2 * np.pi * X['day_of_week'] / 7)\n",
    "        X['day_of_week_cos'] = np.cos(2 * np.pi * X['day_of_week'] / 7)\n",
    "        X['hour_of_day_sin'] = np.sin(2 * np.pi * X['hour_of_day'] / 24)\n",
    "        X['hour_of_day_cos'] = np.cos(2 * np.pi * X['hour_of_day'] / 24)\n",
    "        # 删除原始时间特征\n",
    "        X = X.drop(columns=['month', 'day_of_week', 'hour_of_day'], axis=1)\n",
    "        # 选择用于聚类的特征\n",
    "        clustering_features = ['summertime', 'temp', 'dew', 'humidity', 'snowdepth', 'windspeed', 'cloudcover', 'visibility', 'precip', 'snow']\n",
    "        # 使用训练好的 KMeans 进行预测\n",
    "        X['weather_cluster'] = self.kmeans.predict(X[clustering_features])\n",
    "        # 映射聚类标签到天气质量\n",
    "        X['weather_quality'] = X['weather_cluster'].apply(self.label_weather_cluster)\n",
    "        # One-Hot 编码\n",
    "        weather_dummies = pd.get_dummies(X['weather_quality'], prefix='weather', drop_first=True)\n",
    "        # 确保测试数据的列与训练数据一致\n",
    "        for col in self.weather_dummies_columns:\n",
    "            if col not in weather_dummies.columns:\n",
    "                weather_dummies[col] = 0\n",
    "        X = pd.concat([X, weather_dummies], axis=1)\n",
    "        # 转换布尔类型\n",
    "        for col in X.select_dtypes(include=['bool']).columns:\n",
    "            X[col] = X[col].astype(int)\n",
    "        # 标准化\n",
    "        X_scaled = self.scaler.transform(X[self.numeric_features])\n",
    "        X_scaled = pd.DataFrame(X_scaled, columns=self.numeric_features, index=X.index)\n",
    "        # 组合特征\n",
    "        X_processed = pd.concat([X[self.categorical_features], X_scaled], axis=1)\n",
    "        return X_processed\n",
    "\n",
    "    def label_weather_cluster(self, cluster_label):\n",
    "        if cluster_label == 1:\n",
    "            return 'bad_weather'\n",
    "        elif cluster_label == 0:\n",
    "            return 'good_weather'\n",
    "        elif cluster_label == 2:\n",
    "            return 'neutral_weather'\n",
    "\n",
    "# 模型评估函数\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=['low_bike_demand', 'high_bike_demand'])\n",
    "    return accuracy, f1, report\n",
    "\n",
    "# 超参数调优函数\n",
    "def tune_random_forest_rs(X_train, y_train, cv=5, scoring='f1', n_iter=100):\n",
    "    num_pos = np.sum(y_train == 1)\n",
    "    num_neg = np.sum(y_train == 0)\n",
    "    ratio = num_neg / num_pos\n",
    "    param_dist = {\n",
    "        'classifier__n_estimators': [5 * i for i in range(100, 150)],\n",
    "        'classifier__max_depth': list(range(15, 25)),\n",
    "        'classifier__min_samples_split': list(range(3, 32)),\n",
    "        'classifier__min_samples_leaf': list(range(3, 32)),\n",
    "        'classifier__max_features': ['sqrt', 'log2', 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        'classifier__bootstrap': [True, False],\n",
    "        'classifier__class_weight': ['balanced', {0: 1, 1: ratio}, {0: 1 / ratio, 1: 1}, {0: 1, 1: 1}],\n",
    "        'classifier__criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        'classifier__warm_start': [True, False],\n",
    "    }\n",
    "    # 创建 Pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', CustomPreprocessor()),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    random_search.fit(X_train, y_train.ravel())\n",
    "    return random_search.best_estimator_\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据\n",
    "    data = pd.read_csv('data/training_data_fall2024.csv')\n",
    "    \n",
    "    # 定义特征和目标变量\n",
    "    X_all = data.copy()\n",
    "    y_all = data['increase_stock'].map({'low_bike_demand': 0, 'high_bike_demand': 1}).to_numpy().ravel()\n",
    "    X_all = X_all.drop(columns=['increase_stock'])\n",
    "    \n",
    "    # 超参数调优\n",
    "    print(\"Tuning Random Forest...\")\n",
    "    best_model = tune_random_forest_rs(X_all, y_all, cv=10, scoring='f1', n_iter=100)\n",
    "    \n",
    "    # 使用交叉验证预测\n",
    "    y_pred = cross_val_predict(best_model, X_all, y_all, cv=10)\n",
    "    \n",
    "    # 评估模型\n",
    "    accuracy, f1, report = evaluate_model(y_all, y_pred)\n",
    "    print(f\"Cross-validated Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Cross-validated F1 Score: {f1:.2f}\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_all, y_pred))\n"
   ],
   "id": "70f8854713946421",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=7.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Accuracy: 0.86\n",
      "Cross-validated F1 Score: 0.68\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " low_bike_demand       0.95      0.88      0.91      1312\n",
      "high_bike_demand       0.58      0.80      0.68       288\n",
      "\n",
      "        accuracy                           0.86      1600\n",
      "       macro avg       0.77      0.84      0.79      1600\n",
      "    weighted avg       0.89      0.86      0.87      1600\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1148  164]\n",
      " [  57  231]]\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
